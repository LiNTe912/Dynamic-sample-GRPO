- reward_model.reward_manager=batch
- +reward_model.reward_kwargs.count_file=count/DS-GRPO-Qwen3-4B/nq-open/count.json
- custom_reward_function.path=/dev_data/wy/zwt/verl/verl/utils/reward_score/ds.py
- data.train_files=data/nq_open/train.parquet
- data.val_files=data/nq_open/test.parquet
- data.max_prompt_length=512
- data.max_response_length=1024
- data.train_batch_size=1
- data.filter_overlong_prompts=True
- data.truncation=error
- actor_rollout_ref.model.path=/dev_data/wy/zwt/qwen3-4b
- actor_rollout_ref.model.enable_gradient_checkpointing=True
- actor_rollout_ref.model.use_remove_padding=True
- actor_rollout_ref.actor.ppo_mini_batch_size=1
- actor_rollout_ref.actor.ppo_micro_batch_size_per_gpu=2
- actor_rollout_ref.model.lora_rank=64
- actor_rollout_ref.model.lora_alpha=32
- actor_rollout_ref.actor.use_kl_loss=True
- actor_rollout_ref.actor.optim.lr=5e-7
- actor_rollout_ref.actor.optim.lr_warmup_steps_ratio=0.03
- actor_rollout_ref.actor.optim.warmup_style=cosine
- actor_rollout_ref.actor.fsdp_config.param_offload=False
- actor_rollout_ref.actor.fsdp_config.optimizer_offload=False
- actor_rollout_ref.actor.ppo_max_token_len_per_gpu=1536
- actor_rollout_ref.ref.log_prob_micro_batch_size_per_gpu=2
- actor_rollout_ref.ref.fsdp_config.param_offload=True
- actor_rollout_ref.rollout.name=vllm
- actor_rollout_ref.rollout.temperature=0.6
- actor_rollout_ref.rollout.enforce_eager=False
- actor_rollout_ref.rollout.free_cache_engine=False
- actor_rollout_ref.rollout.log_prob_micro_batch_size_per_gpu=2
- actor_rollout_ref.rollout.tensor_model_parallel_size=1
- actor_rollout_ref.rollout.gpu_memory_utilization=0.8
- actor_rollout_ref.rollout.n=8
- actor_rollout_ref.rollout.max_model_len=1536
- actor_rollout_ref.rollout.max_num_batched_tokens=1536
- critic.optim.lr=9e-6
- critic.model.use_remove_padding=True
- critic.model.path=/dev_data/wy/zwt/qwen3-4b
- critic.model.enable_gradient_checkpointing=True
- critic.ppo_micro_batch_size_per_gpu=2
- critic.model.fsdp_config.param_offload=False
- critic.model.fsdp_config.optimizer_offload=False
- algorithm.kl_ctrl.kl_coef=0.00
- algorithm.adv_estimator=grpo
- trainer.logger=[console]
- trainer.project_name=DS-verl
- trainer.experiment_name=0627-DS-GRPO-DS-GRPO-Qwen3-4B-grpo
- trainer.n_gpus_per_node=1
- trainer.nnodes=1
- trainer.save_freq=200
- trainer.test_freq=100
- trainer.default_local_dir=checkpoints/DS-verl/DS-GRPO-Qwen3-4B/0627/DS-GRPO-grpo-113144
- trainer.total_epochs=3
